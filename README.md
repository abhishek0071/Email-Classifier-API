# EmailÂ ClassifierÂ APIÂ (âš¡Â FastAPIÂ +Â ğŸ¦™Â Ollama)

A lightweight, **CPUâ€‘only** service that classifies incoming eâ€‘mails (e.g. *spam*, *authentic*, *phishing*) using local **LLM models** served byÂ Ollama.Â It is productionâ€‘ready yet hackableâ€”swap models per request, retrain monthly, or scale out via Docker Compose.

---

## âœ¨Â KeyÂ Features

| Capability                 | Details                                                                          |
| -------------------------- | -------------------------------------------------------------------------------- |
| **Multiâ€‘model**            | Pass `?model=gemma3:1b`, `llama3:8b`, or any custom GGUFâ€”you decide per request. |
| **CPUâ€‘friendly**           | Works on a t2.micro or RaspberryÂ Pi; set `OLLAMA_CPU_ONLY=true`.                 |
| **Lazy pulling & caching** | First request for a model triggers `ollama pull`; future calls are instant.      |
| **Clear folder structure** | Domain logic, API layer, and infra wrappers live in separate packages.           |
| **Dockerised**             | Oneâ€‘command spinâ€‘up via `dockerâ€‘compose up --build`.                             |
| **Observabilityâ€‘ready**    | Add `prometheus-fastapi-instrumentator` in seconds for `/metrics`.               |

---

## ğŸ—‚ï¸Â RepositoryÂ Layout

```
email-classifier/
â”œâ”€ app/                # Python package
â”‚  â”œâ”€ core/            # settings & logging
â”‚  â”œâ”€ models/          # Pydantic schemas
â”‚  â”œâ”€ services/        # model registry & business logic
â”‚  â”œâ”€ api/v1/          # versioned REST endpoints
â”‚  â””â”€ main.py          # FastAPI factory
â”œâ”€ tests/              # pytest suite
â”œâ”€ Dockerfile          # app image
â”œâ”€ docker-compose.yml  # app + Ollama
â”œâ”€ requirements.txt    # pinned deps
â””â”€ README.md           # you are here
```

---

## ğŸš€Â QuickÂ Start

### 1Â Â·Â Clone &Â run locally (nativeÂ Ollama)

```sh
# prerequisites: PythonÂ 3.12+, OllamaÂ 0.6+
ollama serve &                      # start daemon in the background
ollama pull gemma3:1b llama3:8b     # or any models you like

python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
uvicorn app.main:app --reload       # http://localhost:8000/docs
```

\###Â 2Â Â·Â DockerÂ Compose

```sh
git clone https://github.com/abhishek0071/Email-Classifier-API.git
cd email-classifier

# first run may take a minute while models download
docker compose up --build
```

Visit **[http://localhost:8000/docs](http://localhost:8000/docs)** for an interactive SwaggerÂ UI.

---

## ğŸ”ŒÂ EnvironmentÂ Variables

| Variable         | Default               | Purpose                            |
| ---------------- | --------------------- | ---------------------------------- |
| `OLLAMA_URL`     | `http://ollama:11434` | Base URL for the Ollama daemon     |
| `DEFAULT_MODEL`  | `gemma3:1b`           | Fallback model when none specified |
| `ALLOWED_MODELS` | `gemma3:1b,llama3:8b` | Commaâ€‘separated allowâ€‘list         |
| `MAX_TOKENS`     | `3000`                 | Clip generation length             |

Create a **.env** file or set them in `docker-compose.yml`.

---

## ğŸ“¡Â APIÂ Usage

### POSTÂ `/v1/classify`

Classify an eâ€‘mail with optional model override.

```sh
curl -X POST 'localhost:8000/v1/classify?model=llama3:8b' \
     -H 'Content-Type: application/json' \
     -d '{"subject":"Win","body":"You have won a prizeâ€¦"}'
# â†’ {"label":"spam","model_used":"llama3:8b","latency_ms":87.4}
```

Check Swagger docs or `tests/test_classifier.py` for more examples.

---

## ğŸ§©Â AddingÂ NewÂ Models

1. Convert your HuggingÂ Face checkpoint to **GGUF** (quantised):

```sh
   python llama.cpp/convert.py <HF_MODEL> --outfile myspam.gguf --outtype q4_0
```

2. Register with Ollama:

```sh
   ollama create myspam --path myspam.gguf
```

3. Append to `ALLOWED_MODELS` and youâ€™re doneâ€”no code change needed.

---

## ğŸ› ï¸Â Testing

```sh
pip install pytest
pytest -q
```

---

## ğŸ—ï¸Â ProductionÂ Tips

* **Gunicorn workers** â†’ `gunicorn -k uvicorn.workers.UvicornWorker app.main:app -w 4 -b 0.0.0.0:8000`
* **Observability** â†’

```python
  from prometheus_fastapi_instrumentator import Instrumentator
  Instrumentator().instrument(app).expose(app)
```

* **Rateâ€‘limit** with `slowapi` or an API gateway.
* **Secure** Ollama & API ports behind a VPN or reverse proxy with mTLS.
* **Background retrain** via Celery + cron; on completion call `ollama create spamâ€‘v2 â€¦`.

---

## ğŸ¤Â Contributing

PRs and issues are welcome! Please format with `ruff`, run `pytest`, and update docs.

---

## ğŸ“„Â License

MIT Â©Â 2025Â YourÂ Name / Webappclouds Software Solution Pvt Ltd